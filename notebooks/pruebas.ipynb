{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from torchmetrics) (2.2.0)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.10.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\facua\\anaconda3\\envs\\textract\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
      "   ---------------------------------------- 0.0/840.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 10.2/840.4 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 92.2/840.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 225.3/840.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 368.6/840.4 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 593.9/840.4 kB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 778.2/840.4 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  839.7/840.4 kB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 840.4/840.4 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.10.1 torchmetrics-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\facua\\anaconda3\\envs\\textract\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.data import metrics \n",
    "preds = ['cat']\n",
    "truth = 'cat'\n",
    "target = [['cat']]\n",
    "bleu = metrics.bleu_score(preds, target)\n",
    "bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "# Predicción (debe ser una lista de tokens)\n",
    "candidate = [\"this\"]\n",
    "\n",
    "# Referencias (una lista de listas de tokens)\n",
    "references = [[\"this\", \"is\", \"a\", \"test\"]]\n",
    "\n",
    "# Calcular BLEU score\n",
    "score = bleu_score(candidate, references)\n",
    "\n",
    "print(f\"BLEU score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[38;5;28;01mdel\u001b[39;00m toks[b][i]\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m toks\n\u001b[1;32m---> 13\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m PreTrainedTokenizerFast(tokenizer_file\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[0;32m     14\u001b[0m pred \u001b[38;5;241m=\u001b[39m detokenize(dec, tokenizer)\n\u001b[0;32m     15\u001b[0m truth \u001b[38;5;241m=\u001b[39m detokenize(seq[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], tokenizer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "def detokenize(tokens, tokenizer):\n",
    "    toks = [tokenizer.convert_ids_to_tokens(tok) for tok in tokens]\n",
    "    for b in range(len(toks)):\n",
    "        for i in reversed(range(len(toks[b]))):\n",
    "            if toks[b][i] is None:\n",
    "                toks[b][i] = ''\n",
    "            toks[b][i] = toks[b][i].replace('Ġ', ' ').strip()\n",
    "            if toks[b][i] in (['[BOS]', '[EOS]', '[PAD]']):\n",
    "                del toks[b][i]\n",
    "    return toks\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"model/dataset/tokenizer.json\")\n",
    "pred = detokenize(dec, tokenizer)\n",
    "truth = detokenize(seq['input_ids'], tokenizer)\n",
    "#bleus.append(metrics.bleu_score(pred, [alternatives(x) for x in truth]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\\\{ [ R , R , R ] \\\\} = 0 , \\\\ \\\\ R ( K , J ) ^ { - 1 } = R ( J , K ) ^ { + } \\mathrm { f o r } \\\\ J \\neq K .']$\n",
    "$ ['( ( R x , R ) ) = 0 , ~ R ( X , y ) - 1 = R ( y , X ) + B ( y , Y )']$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
