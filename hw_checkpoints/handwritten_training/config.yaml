backbone_layers:
- 2
- 3
- 7
batchsize: 64
betas:
- 0.9
- 0.999
bos_token: 1
channels: 1
config: pix2tex/model/settings/handwritten_training.yaml
data: dataset/handwritten/train_hw.pkl
debug: false
decoder_args:
  attn_on_attn: true
  cross_attend: true
  ff_glu: true
  rel_pos_bias: false
  use_scalenorm: false
device: cpu
dim: 256
encoder_depth: 4
encoder_structure: hybrid
eos_token: 2
epoch: 18
epochs: 100
gamma: 0.9995
gpu_devices: []
heads: 8
id: lm6bcnat
load_chkpt: pix2tex/model/checkpoints/weights.pth
lr: 0.001
lr_step: 30
max_dimensions:
- 672
- 192
max_height: 192
max_seq_len: 512
max_width: 672
micro_batchsize: -1
min_dimensions:
- 32
- 32
min_height: 32
min_width: 32
model_path: hw_checkpoints
name: handwritten_training
no_cuda: false
num_layers: 4
num_tokens: 8000
optimizer: Adam
output_path: hw_outputs
pad: false
pad_token: 0
patch_size: 16
resume: false
sample_freq: 3000
save_freq: 50
scheduler: StepLR
seed: 42
temperature: 0.2
test_samples: 5
testbatchsize: 20
tokenizer: dataset/tokenizer.json
valbatches: 100
valdata: dataset/handwritten/val_hw.pkl
wandb: true
